{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pndang/llm-comet/blob/main/advanced_prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJUgpXEq75iG"
      },
      "source": [
        "# Overview of Prompt Engineering Techniques & Best Practices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxBHRaGL75iJ"
      },
      "source": [
        "## Part 2: Prompt Engineering Techniques\n",
        "\n",
        "In this section, we cover the best prompt engineering techniques and how to apply them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUb6m_OT75iK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9m-55tj75iK"
      },
      "source": [
        "We first load the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai==0.28 langchain google-search-results chromadb tiktoken --quiet"
      ],
      "metadata": {
        "id": "omekMCDE7_86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b92550-951c-4ed9-b60b-2de6f354583d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "k9oO2J6675iL"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# API configuration\n",
        "openai.api_key ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FVCiytVV75iM"
      },
      "outputs": [],
      "source": [
        "# completion function\n",
        "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JdLUeuU75iM"
      },
      "source": [
        "### Few-shot In-Context Learning\n",
        "\n",
        "Below we provide an example of few-shot prompting with demonstrations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4IxjDiXQ75iN",
        "outputId": "89ec1bb6-8712-4135-9fd3-b21eefd336c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "non-offensive\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Your task is to classify an input text (delimited by ```) as either offensive or non-offensive.\n",
        "\n",
        "Use the following examples to help with steering your responses:\n",
        "\n",
        "Text: I love you\n",
        "Output: non-offensive\n",
        "\n",
        "Text: I dislike all those people working at the company\n",
        "Output: offensive\n",
        "\n",
        "Text: I think this feature is not ideal\n",
        "Output: non-offensive\n",
        "\n",
        "Text: Those people are so stupid\n",
        "Output: offensive\n",
        "\n",
        "Text: {user_input}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt.format(\n",
        "            user_input=\"```I respectfully disagree with your opinion.```\"\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWARCtrw75iO"
      },
      "source": [
        "### Chain-of-Though (CoT) Prompting\n",
        "\n",
        "Below is an example of CoT applied. Specifically, we aim to build a movie recommendation system using CoT.\n",
        "\n",
        "Let's first define a set of movies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "h252IuDV75iO"
      },
      "outputs": [],
      "source": [
        "movies = \"\"\"\n",
        "The Enigma Code\n",
        "Category: Historical Drama\n",
        "Rating: 8.3/10\n",
        "Description: Set during World War II, this gripping historical drama follows the life of Alan Turing, a brilliant mathematician tasked with cracking the Enigma code used by the Nazis. His efforts contribute significantly to the Allies' victory.\n",
        "Actors: Benedict Cumberbatch, Keira Knightley, Matthew Goode\n",
        "Language: English\n",
        "Release Date: March 15, 2014\n",
        "Award Winner: Academy Award for Best Adapted Screenplay\n",
        "\n",
        "Shadows of the Samurai\n",
        "Category: Action/Adventure\n",
        "Rating: 7.9/10\n",
        "Description: In feudal Japan, a skilled samurai seeks vengeance against the corrupt warlord who murdered his master. With his swordsmanship and determination, he embarks on a dangerous journey to restore justice.\n",
        "Actors: Ken Watanabe, Tadanobu Asano, Rinko Kikuchi\n",
        "Language: Japanese\n",
        "Release Date: November 7, 2017\n",
        "Award Winner: None\n",
        "\n",
        "Mind Games\n",
        "Category: Psychological Thriller\n",
        "Rating: 8.1/10\n",
        "Description: A renowned psychologist becomes entangled in a twisted game of cat and mouse with a patient who harbors dark secrets. As their sessions progress, the lines between reality and deception blur, leading to a mind-bending climax.\n",
        "Actors: Leonardo DiCaprio, Natalie Portman, Michael Fassbender\n",
        "Language: English\n",
        "Release Date: August 22, 2019\n",
        "Award Winner: None\n",
        "\n",
        "La Casa del Tango\n",
        "Category: Musical/Drama\n",
        "Rating: 8.7/10\n",
        "Description: In the vibrant world of Buenos Aires, a passionate tango dancer finds love and inspiration amidst the backdrop of political unrest. This musical drama explores the power of dance and the pursuit of dreams.\n",
        "Actors: Antonio Banderas, Penélope Cruz, Javier Bardem\n",
        "Language: Spanish\n",
        "Release Date: June 5, 2020\n",
        "Award Winner: Golden Globe for Best Foreign Language Film\n",
        "\n",
        "Timeless Love\n",
        "Category: Romance/Fantasy\n",
        "Rating: 7.5/10\n",
        "Description: A magical encounter transports a modern-day writer back in time to Victorian England, where she falls in love with a charming aristocrat. As they navigate the complexities of time, their love is put to the ultimate test.\n",
        "Actors: Rachel McAdams, Tom Hiddleston, Emma Thompson\n",
        "Language: English\n",
        "Release Date: February 14, 2022\n",
        "Award Winner: None\n",
        "\n",
        "The Pursuit of Justice\n",
        "Category: Legal Drama\n",
        "Rating: 8.4/10\n",
        "Description: Inspired by true events, this gripping legal drama follows a determined lawyer's fight against a powerful pharmaceutical company responsible for a life-threatening drug. The courtroom battle becomes a quest for justice and redemption.\n",
        "Actors: Denzel Washington, Viola Davis, Michael B. Jordan\n",
        "Language: English\n",
        "Release Date: October 10, 2022\n",
        "Award Winner: None\n",
        "\n",
        "The Forgotten Island\n",
        "Category: Adventure/Mystery\n",
        "Rating: 7.6/10\n",
        "Description: A group of explorers stumbles upon a mysterious island believed to be uninhabited. As they uncover the island's secrets, they encounter deadly challenges and unravel an ancient civilization's enigma.\n",
        "Actors: Chris Pratt, Bryce Dallas Howard, Tom Holland\n",
        "Language: English\n",
        "Release Date: July 2, 2023\n",
        "Award Winner: None\n",
        "\n",
        "The Silent Witness\n",
        "Category: Crime/Thriller\n",
        "Rating: 8.2/10\n",
        "Description: A talented forensic pathologist becomes entangled in a high-stakes murder investigation when she discovers crucial evidence that points to a powerful criminal network. With her life on the line, she must outsmart the perpetrators.\n",
        "Actors: Emily Blunt, Jake Gyllenhaal, Mark Ruffalo\n",
        "Language: English\n",
        "Release Date: November 18, 2023\n",
        "Award Winner: None\n",
        "\n",
        "A Tale of Two Worlds\n",
        "Category: Fantasy/Adventure\n",
        "Rating: 7.8/10\n",
        "Description: When a young orphan discovers a magical portal to a parallel universe, she embarks on a thrilling adventure to save both realms from an impending disaster. Along the way, she learns about the power of friendship and self-belief.\n",
        "Actors: Millie Bobby Brown, Tom Holland, Helena Bonham Carter\n",
        "Language: English\n",
        "Release Date: April 5, 2024\n",
        "Award Winner: None\n",
        "\n",
        "A Symphony of Souls\n",
        "Category: Music/Drama\n",
        "Rating: 9.0/10\n",
        "Description: Set against the backdrop of a renowned symphony orchestra, this emotionally charged drama explores the lives and intertwining stories of its members. Through the power of music, they find solace, love, and redemption.\n",
        "Actors: Meryl Streep, Tom Hanks, Cate Blanchett\n",
        "Language: English\n",
        "Release Date: December 25, 2024\n",
        "Award Winner: None\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq9J_ESe75iP"
      },
      "source": [
        "We then take those movies and list the different steps the model should perform. Notice that the after detailing the steps, we ask the model to providing the reasoning steps and the final response. This is a format you can use to elicit reasoning in LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZxmNzJ7775iQ",
        "outputId": "7fae646e-fd77-4494-9c51-54d4b8aaaad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: The user is asking about movies.\n",
            "\n",
            "Step 2: The user is specifically asking for drama movies.\n",
            "\n",
            "Step 3: Based on your interest in drama movies, I recommend the following movie:\n",
            "- **The Enigma Code**\n",
            "  - Category: Historical Drama\n",
            "  - Rating: 8.3/10\n",
            "  - Description: Set during World War II, this gripping historical drama follows the life of Alan Turing, a brilliant mathematician tasked with cracking the Enigma code used by the Nazis. His efforts contribute significantly to the Allies' victory.\n",
            "  - Actors: Benedict Cumberbatch, Keira Knightley, Matthew Goode\n",
            "  - Language: English\n",
            "  - Release Date: March 15, 2014\n",
            "  - Award Winner: Academy Award for Best Adapted Screenplay\n",
            "\n",
            "Step 4: I recommend watching \"The Enigma Code\" for a captivating drama experience with a historical backdrop. Enjoy the brilliant performances and the gripping storyline!\n"
          ]
        }
      ],
      "source": [
        "# the system message contains the logic (step by step) for the system to follow\n",
        "system_message = \"\"\"\n",
        "You task is to make movie recommendations based on a user request (delimited by ```).\n",
        "\n",
        "Step 1: Check if the user is asking about movies. If the user is not asking about movies, just respond \"Please ask something about movies!\".\n",
        "\n",
        "Step 2: If the user is asking for a movie recommendation, check if they have any specific requests or interests.\n",
        "\n",
        "Step 3: Check if there are any movie/s we can recommend from the following: {movies}\n",
        "\n",
        "Step 4: Prepare a response to the user with the movie recommendation/s. The recommendation have to be about movies that are available in the list above. The response needs to have a friendly and helpful tone.\n",
        "\n",
        "Return a response with the following reasoning steps and final output to the user:\n",
        "Step 1: <Step 1 reasoning>\n",
        "Step 2: <Step 2 reasoning>\n",
        "Step 3: <Step 3 reasoning>\n",
        "Step 4: <final response>\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message.format(movies=movies)\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"```Do you have any drama movies?```\"\n",
        "    }\n",
        "]\n",
        "\n",
        "movie_recommendation_response = get_completion(messages, temperature=0, max_tokens=500)\n",
        "\n",
        "print(movie_recommendation_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PO6l0hZ75iQ"
      },
      "source": [
        "### Prompt Chaining\n",
        "\n",
        "The example below demonstrates how to chain separate prompts to achieve a specific task. The previous prompt list all the reasoning steps. In the following prompt, we ask the model to extract only the final response to the user:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "j8w10Dwy75iQ",
        "outputId": "3029aa78-2e56-4c07-f5c5-c9eb7eee3f7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I recommend watching \"The Enigma Code\" for a captivating drama experience with a historical backdrop. Enjoy the brilliant performances and the gripping storyline!\n"
          ]
        }
      ],
      "source": [
        "# Prompt 1: step by step reasoning (provided above)\n",
        "# Prompt 2: extract only the final response we will send to the user\n",
        "\n",
        "system_message_2 = \"\"\"\n",
        "You will be given a list of steps that a model has responded with. Your task is to extract only the full response in Step 4 from the following text: {movie_recommendation_response}\n",
        "\n",
        "Step 4:\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message_2.format(movie_recommendation_response=movie_recommendation_response)\n",
        "    }\n",
        "]\n",
        "\n",
        "final_response = get_completion(messages, temperature=0)\n",
        "\n",
        "print(final_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imAdMD4375iR"
      },
      "source": [
        "### ReAct\n",
        "\n",
        "The code below shows an example of combining LLMs with external tools to achieve a task. In particular, the example uses the ReAct framework to prompt and guide the model to the result by leveraging the LLM and a search engine. We will be using SerpAPI in the below example. As mentioned in the course introduction, you will need to register for a free account with SerpAPI to complete this part of the exercise. You can [register here](https://serpapi.com/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install langchain-community"
      ],
      "metadata": {
        "id": "TIHrQsCa1TQs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "htgE9zNN75iR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff900822-c906-4602-904d-293e26f10fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "# for LangChain\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key      # needs key from OpenAI\n",
        "os.environ[\"SERPAPI_API_KEY\"] =\n",
        "\n",
        "# model\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# tools\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "agent = initialize_agent(tools, llm , agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eUyQ1DSH75iR",
        "outputId": "621f2854-c650-4a27-dcf1-246ec13954e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should search for the answer using a search engine.\n",
            "Action: Search\n",
            "Action Input: \"2023 NBA finals winner\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDenver Nuggets\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should double check this information using a different source.\n",
            "Action: Search\n",
            "Action Input: \"2023 NBA finals winner\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDenver Nuggets\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to confirm the year.\n",
            "Action: Calculator\n",
            "Action Input: 2023\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2023\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The Denver Nuggets won the 2023 NBA finals.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Denver Nuggets won the 2023 NBA finals.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# run the agent\n",
        "agent.run(\"Which team won the 2023 NBA finals?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Who is a king or emperor of Vietnam with the most positive impact on the country?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "8hOEs7pE4HAq",
        "outputId": "b33280d6-aa4e-40e0-a3e1-8c0127ab5303"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use a search engine to find information about kings and emperors of Vietnam.\n",
            "Action: Search\n",
            "Action Input: \"kings and emperors of Vietnam with positive impact\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['The reason for this is because the title “King” was granted by Chinese emperor and by using it, Vietnam would be seen as a vassal state or even ...', 'China, by then ruled by emperors of the Ming dynasty (1368–1644), seized this opportunity to invade Dai Viet again in 1407. The Ming rulers reestablished direct ...', 'From 1949 to 1955, Bảo Đại was the chief of state of the non-communist State of Vietnam. Viewed as a puppet ruler, Bảo Đại was criticized for being too closely ...', 'The nearly one-thousand-year period of Chinese rule had some profound impacts on Vietnamese culture, and this was no accident. China was very confident in its ...', 'Nguyen Anh came to the throne, proclaiming himself Emperor under the title of Gia Long, having inherited a unified country which had developed ...', 'Abstract: The Nguyen Dynasty was the last monarchy in Vietnamese history, established after Nguyen Anh ascended the throne in 1802 and ended ...', 'ABSTRACT. The singularity of the Vietnamese revolution cannot be explained entirely by factors such as a racially discriminating colonialism or.', \"Despite public criticism, King continued to attack the Vietnam War on both moral and economic grounds. Footnotes. Branch, At Canaan's Edge, 2006. “Dr. King's ...\", 'List of monarchs of Vietnam ; Kinh Dương Vương (as King) (Mythical) Zhao Tuo (as Emperor) (Historical but still controversial) · Bảo Đại (as Emperor) · 2879 BC ( ...', 'As two local Vietnamese leaders of the Ly dynasty, Nung Tri Hoi and Nung Ton Dan, brought land and people fled to the Song dynasty, the kings of ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should read through the observations to find the answer.\n",
            "Action: Search\n",
            "Action Input: \"Nguyen Anh positive impact Vietnam\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Nguyen Anh is also much blamed for the later colonization of Vietnam by France, with the presence of a few Frenchmen who held top positions ...', 'Abstract. In 2010, Vietnam achieved a total import-export turnover of US $ 154 billion, but by 2019, that number increased more than tripled ...', '... Nguyen Anh in wresting control of Dai Viet from the Tay Sons. Upon becoming emperor, however, Nguyen Anh (now Gia Long) did not favour Christianity. Under ...', 'This research showed that FTA between EU and ASEAN will have positive impacts on both EU and ASEAN, of which more benefits will be gained by ASEAN countries ( ...', 'He hopes to contribute his expertise to national sustainable development and create a positive impact on climate change in Viet Nam.', \"Vietnamese feudalism was on the decline during the Nguyen dynasty's reign in the mid-nineteenth century, and the situation became even more difficult when ...\", 'The Nguyen defeat last of Tay Son forces. Nguyen Anh accedes to throne as Gia Long and establishes his capital at Hue. 1802—1945.', 'Marketing Researcher · I was born and raised in the exciting Vietnamese capital of Ho Chi Minh City, which is one of the main economic powerhouses in Asia.', 'Since the country opened its doors to foreign trade in the late 1980s, Vietnam has experienced rapid economic growth and an influx of ...', 'Vietnam is a developing country with a lower-middle-income economy. It has high levels of corruption, censorship, environmental issues and a poor human rights ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use a search engine to find information about the positive impacts of Nguyen Anh on Vietnam.\n",
            "Action: Search\n",
            "Action Input: \"positive impacts Nguyen Anh Vietnam\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Pigneau de Behaine went to France to obtain military aid, and secured a France-Vietnam alliance that was signed through the 1787 Treaty of Versailles between ...', 'Nguyen Anh is also much blamed for the later colonization of Vietnam by France, with the presence of a few Frenchmen who held top positions ...', 'From Gia Long to Tu Duc, the Nguyen kings successively built and consolidated their dominance, protecting the feudal system in the midst of a decline.', 'Like previous regimes, the Nguyen dynasty attached importance to the development of agricultural production with waste land reclaimed, canals ...', 'In a series of campaigns that lasted 14 years, Nguyen Anh defeated the Tay Sons and gained control of the entire kingdom. When Hue and Thang Long fell to his ...', 'The positive aspect is his desire for an independent Vietnam ... Nguyen Giap,who defeated French,Americans ,Chinese to defend Vietnam.', 'was clearly ineffective, as it resulted in negative consequences for the Nguyen dynasty and the country. Xuan Hiep et al., Cogent Arts ...', 'From Southern Vietnam, Nguyen Anh began to push northwards. The Nguyen Anh campaigned for a decade. He had developed a good management skills ...', \"Tuan is GIZ's NDC-TIA project officer under Vietnam component. He is responsible for coordinating the activities regarding electric mobility and ...\", 'The empirical results show that return on assets, tangible assets, risks, and growth have a statistically significant positive effect on the firm capital ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to find the final answer.\n",
            "Action: Calculator\n",
            "Action Input: \"14 years\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 14\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Nguyen Anh had a positive impact on Vietnam for 14 years.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nguyen Anh had a positive impact on Vietnam for 14 years.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNN3743a75iS"
      },
      "source": [
        "### Data Augmentation / RAG\n",
        "\n",
        "The example below demonstrates how to apply data augmented generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R4DyoBH75iS"
      },
      "source": [
        "We first load the necessary LangChain modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nf0ViFQH75iS"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings.cohere import CohereEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0euIhOy75iS"
      },
      "source": [
        "Next, we split the loaded text file into chunks and embed the chunks using OpenAI Embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zjqiX2_-75iS"
      },
      "outputs": [],
      "source": [
        "# load the data from GitHub\n",
        "import urllib\n",
        "f = urllib.request.urlopen(\"https://raw.githubusercontent.com/comet-ml/comet-llmops/main/data/kar-gpt.txt\")\n",
        "text_data = f.read().decode(\"utf-8\")\n",
        "\n",
        "# split text into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator=\" \")\n",
        "texts = text_splitter.split_text(text_data)\n",
        "\n",
        "# embeddings obtained from OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAdBa3Fc75iT"
      },
      "source": [
        "The next step is to store the embeddings into Chroma, a dedicated vector storage. And finally, we perform a search by querying Chroma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QcigNs2e75iT",
        "outputId": "92b4517a-93a9-44ef-9177-8e93c678e9ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output_text': ' The course is about fine tuning and language models.\\nSOURCES: 108, 1'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# test search\n",
        "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))])\n",
        "\n",
        "query = \"What is the course about?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "\n",
        "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4lwx8D2q3g63"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "comet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "name": "advanced-prompt-engineering.ipynb",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}